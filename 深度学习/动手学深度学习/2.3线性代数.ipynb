{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3. 线性代数\n",
    "### 2.3.1. 标量\n",
    "![image_122](./assets/Snipaste_2023-12-04_16-22-26.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1da9e2e5cb9916fc"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.)\n",
      "tensor(1.)\n",
      "tensor(6.)\n",
      "tensor(1.5000)\n",
      "tensor(9.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(3.0)\n",
    "y = torch.tensor(2.0)\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "print(x * y)\n",
    "print(x / y)\n",
    "print(x ** y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:05:08.392774Z",
     "start_time": "2023-12-09T02:05:08.346783700Z"
    }
   },
   "id": "fb99911aa3f7b36e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.2. 向量\n",
    "向量可以被视为标量值组成的列表。 这些标量值被称为向量的元素（element）或分量（component）。 当向量表示数据集中的样本时，它们的值具有一定的现实意义。 例如，如果我们正在训练一个模型来预测贷款违约风险，可能会将每个申请人与一个向量相关联， 其分量与其收入、工作年限、过往违约次数和其他因素相对应。 如果我们正在研究医院患者可能面临的心脏病发作风险，可能会用一个向量来表示每个患者， 其分量为最近的生命体征、胆固醇水平、每天运动时间等。 在数学表示法中，向量通常记为粗体、小写的符号 （例如x,y和z).\n",
    "\n",
    "人们通过一维张量表示向量。一般来说，张量可以具有任意长度，取决于机器的内存限制。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a603564baa255e1"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:05:09.663277Z",
     "start_time": "2023-12-09T02:05:09.655592800Z"
    }
   },
   "id": "59e7bfd391eda15c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以使用下标来引用向量的任一元素，例如可以通过x(i)来引用第i个元素。 注意x(i)元素\n",
    "是一个标量，所以我们在引用它时不会加粗。 大量文献认为列向量是向量的默认方向，在本书中也是如此。 在数学中，向量\n",
    "x可以写为：\n",
    "![iamge-13465465](./assets/Snipaste_2023-12-04_16-37-42.png)\n",
    "其中x(1)....x(n)是向量的元素。在代码中，我们通过张量的索引来访问任一元素。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50e6d45704db35b1"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "print(x[3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:05:10.520856600Z",
     "start_time": "2023-12-09T02:05:10.506780200Z"
    }
   },
   "id": "4358a35fd6ff3962"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.2.1 长度,维度和形状\n",
    "![image245adsd](./assets/Snipaste_2023-12-04_16-38-31.png)\n",
    "当用张量表示一个向量（只有一个轴）时，我们也可以通过.shape属性访问向量的长度。 形状（shape）是一个元素组，列出了张量沿每个轴的长度（维数）。 对于只有一个轴的张量，形状只有一个元素。\n",
    "请注意，维度（dimension）这个词在不同上下文时往往会有不同的含义，这经常会使人感到困惑。 为了清楚起见，我们在此明确一下： 向量或轴的维度被用来表示向量或轴的长度，即向量或轴的元素数量。 然而，张量的维度用来表示张量具有的轴数。 在这个意义上，张量的某个轴的维数就是这个轴的长度。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53caeb37a0493def"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(x))\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(x\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(x))\n",
    "print(x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T07:43:47.725568Z",
     "start_time": "2023-12-09T07:43:47.390567600Z"
    }
   },
   "id": "9ac597d6a50980a6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.3. 矩阵\n",
    "\n",
    "![image-asdasdads](./assets/Snipaste_2023-12-04_16-42-30.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2428406c0a87730"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "A = torch.arange(20).reshape(5, 4)\n",
    "print(A)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T07:43:47.726568Z",
     "start_time": "2023-12-09T07:43:47.725568Z"
    }
   },
   "id": "d2cf914f3a175f05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image-asdasdasddasdas](./assets/Snipaste_2023-12-04_17-04-39.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5759c6889c49342"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(A.T)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T07:43:47.726568Z",
     "start_time": "2023-12-09T07:43:47.726568Z"
    }
   },
   "id": "d2118bff8b3df8f9"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "18f40c8c6bc1bf22"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m B \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([[\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m], [\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m4\u001B[39m], [\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m]])\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(B)\n\u001B[0;32m      4\u001B[0m B_T \u001B[38;5;241m=\u001B[39m B\u001B[38;5;241m.\u001B[39mT\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "B = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
    "print(B)\n",
    "\n",
    "B_T = B.T\n",
    "print(B_T)\n",
    "print(B == B_T)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T07:43:47.914439600Z",
     "start_time": "2023-12-09T07:43:47.900947Z"
    }
   },
   "id": "cfba8ddc2f1efdee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.4. 张量\n",
    "当我们开始处理图像时，张量将变得更加重要，图像以\n",
    "维数组形式出现， 其中3个轴对应于高度、宽度，以及一个通道（channel）轴， 用于表示颜色通道（红色、绿色和蓝色）。 现在先将高阶张量暂放一边，而是专注学习其基础知识。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee326774fa7a60a5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m X \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m24\u001B[39m)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(X)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "print(X)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T07:43:49.016731800Z",
     "start_time": "2023-12-09T07:43:49.006505700Z"
    }
   },
   "id": "77a4aaee2220afef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.5. 张量算法的基本性质\n",
    "标量、向量、矩阵和任意数量轴的张量（本小节中的“张量”指代数对象）有一些实用的属性。 例如，从按元素操作的定义中可以注意到，任何按元素的一元运算都不会改变其操作数的形状。 同样，给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量。 例如，将两个相同形状的矩阵相加，会在这两个矩阵上执行元素加法。\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c697e04e21532b21"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m A \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m20\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat32)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m      2\u001B[0m B \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mclone()  \u001B[38;5;66;03m# 通过分配新内存，将A的一个副本分配给B\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(A)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "B = A.clone()  # 通过分配新内存，将A的一个副本分配给B\n",
    "print(A)\n",
    "print(A + B)\n",
    "print(A * 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T07:43:49.934021300Z",
     "start_time": "2023-12-09T07:43:49.923613Z"
    }
   },
   "id": "a8bfebe3fccb80e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image-Hadamard](./assets/Snipaste_2023-12-04_17-28-34.png)\n",
    "将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f572fbe13a12aa78"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m a \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m----> 2\u001B[0m X \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m24\u001B[39m)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(a \u001B[38;5;241m+\u001B[39m X)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m((a \u001B[38;5;241m*\u001B[39m X)\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "a = 2\n",
    "X = torch.arange(24).reshape(2, 3, 4)\n",
    "print(a + X)\n",
    "print((a * X).shape)\n",
    "print(A * B)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T07:43:51.478088600Z",
     "start_time": "2023-12-09T07:43:51.470016200Z"
    }
   },
   "id": "8b5da80a0f999942"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.6. 降维\n",
    "我们可以对任意张量进行的一个有用的操作是计算其元素的和，数学表示法使用∑符号表示求和,为了表示长度为d的向量中元素的综合，可以记为∑(^d)(_i=1){x_i},在代码中可以调用起算求和的函数。\n",
    "![ image-Snipaste_2023-12-04_17-28-555.png ](./assets/Snipaste_2023-12-09_15-44-31.png)\n",
    "默认情况下，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量。 我们还可以指定张量沿哪一个轴来通过求和降低维度。 以矩阵为例，为了通过求和所有行的元素来降维（轴0），可以在调用函数时指定axis=0。 由于输入矩阵沿0轴降维以生成输出向量，因此输入轴0的维数在输出形状中消失。\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b926ccff0600fd30"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "tensor([40., 45., 50., 55.])\n",
      "torch.Size([4])\n",
      "tensor([ 6., 22., 38., 54., 70.])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.arange(4, dtype=torch.float32)\n",
    "x, x.sum()\n",
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis1 = A.sum(axis=1)\n",
    "print(A)\n",
    "print(A_sum_axis0)\n",
    "print(A_sum_axis0.shape)\n",
    "print(A_sum_axis1)\n",
    "print(A_sum_axis1.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:08:38.873907500Z",
     "start_time": "2023-12-09T02:08:38.866641900Z"
    }
   },
   "id": "127bf30a1c9693fc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "沿着行和列对矩阵求和，等价于对矩阵的所有元素进行求和。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69922407d617faf"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(190.)\n"
     ]
    }
   ],
   "source": [
    "A_sum_axis01 = A.sum(axis=[0, 1])  # 结果和A.sum()相同\n",
    "print(A_sum_axis01)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:09:05.024198Z",
     "start_time": "2023-12-09T02:09:05.014730400Z"
    }
   },
   "id": "108e93dea6ef25b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "一个与求和相关的量是平均值（mean或average）。 我们通过将总和除以元素总数来计算平均值。 在代码中，我们可以调用函数来计算任意形状张量的平均值。\n",
    "mean():求平均\n",
    "numel():元素个数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fc76a4ac76baa93"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.5000)\n",
      "tensor(9.5000)\n"
     ]
    }
   ],
   "source": [
    "print(A.mean())\n",
    "print(A.sum() / A.numel())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:09:36.931783200Z",
     "start_time": "2023-12-09T02:09:36.905171300Z"
    }
   },
   "id": "7a09b21552aae353"
  },
  {
   "cell_type": "markdown",
   "source": [
    "同样，计算平均值的函数也可以沿指定轴降低张量的维度。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bd22dde3aeb0aa4"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "tensor([40., 45., 50., 55.])\n",
      "tensor([ 8.,  9., 10., 11.])\n",
      "torch.Size([5, 4])\n",
      "tensor([ 8.,  9., 10., 11.])\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "print(A.sum(axis=0))\n",
    "print(A.mean(axis=0))\n",
    "print(A.shape)\n",
    "print(A.sum(axis=0) / A.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:15:25.066115500Z",
     "start_time": "2023-12-09T02:15:25.058153500Z"
    }
   },
   "id": "4f4613e13eb691c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.3.6.1. 非降维求和\n",
    "但是，有时在调用函数来计算总和或均值时保持轴数不变会很有用。\n",
    "例如，由于sum_A在对每行进行求和后仍保持两个轴，我们可以通过广播将A除以sum_A。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82b19ce1aac7d081"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fc2361fec8ff0dbe"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "tensor([[ 6.],\n",
      "        [22.],\n",
      "        [38.],\n",
      "        [54.],\n",
      "        [70.]])\n",
      "torch.Size([5, 1])\n",
      "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
      "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
      "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
      "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
      "        [0.2286, 0.2429, 0.2571, 0.2714]])\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "sum_A = A.sum(axis=1, keepdims=True)\n",
    "print(sum_A)\n",
    "print(sum_A.shape)\n",
    "\n",
    "A_sum_A = A / sum_A\n",
    "print(A_sum_A)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:19:51.168751900Z",
     "start_time": "2023-12-09T02:19:51.160392Z"
    }
   },
   "id": "f411c8c0308a0dce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果我们想沿某个轴计算A元素的累积总和， 比如axis=0（按行计算），可以调用cumsum函数。 此函数不会沿任何轴降低输入张量的维度。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c414d1976dfa78ab"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]])\n",
      "--------------------\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  6.,  8., 10.],\n",
      "        [12., 15., 18., 21.],\n",
      "        [24., 28., 32., 36.],\n",
      "        [40., 45., 50., 55.]])\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "A_cumsum = A.cumsum(axis=0)\n",
    "print(\"--------------------\")\n",
    "print(A_cumsum)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T02:22:48.629608700Z",
     "start_time": "2023-12-09T02:22:48.619733200Z"
    }
   },
   "id": "59cdcc16c98fdff9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.7. 点积（Dot Product）\n",
    "![image_Snipaste_2023-12-09_10-25-39.png](./assets/Snipaste_2023-12-09_15-44-54.png)\n",
    "\n",
    "点积计算规则： 对应元素相乘的和\n",
    "注意，我们可以通过执行按元素乘法，然后进行求和来表示两个向量的点积\n",
    "![image_Snipaste_2023-12-09_11-05-50.png](./assets/Snipaste_2023-12-09_15-45-11.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de49392b2b79c462"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.])\n",
      "-----------\n",
      "tensor([1., 1., 1., 1.])\n",
      "-----------\n",
      "tensor(6.)\n",
      "-----------\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "y = torch.ones(4, dtype=torch.float32)\n",
    "print(x)\n",
    "print(\"-----------\")\n",
    "print(y)\n",
    "print(\"-----------\")\n",
    "print(torch.dot(x, y))\n",
    "print(\"-----------\")\n",
    "print(torch.sum(x * y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T03:05:34.112972500Z",
     "start_time": "2023-12-09T03:05:34.082804300Z"
    }
   },
   "id": "98960e85b1e602a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.8. 矩阵-向量积\n",
    "![image_Snipaste_2023-12-09_11-08-47.png](./assets/Snipaste_2023-12-09_15-45-27.png)\n",
    "在代码中使用张量表示矩阵-向量积，我们使用mv函数。 当我们为矩阵A和向量x调用torch.mv(A, x)时，会执行矩阵-向量积。 注意，A的列维数（沿轴1的长度）必须与x的维数（其长度）相同。\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa19564daab1fb41"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 14.,  38.,  62.,  86., 110.])\n",
      "---------等同于-------------------\n",
      "tensor([ 14.,  38.,  62.,  86., 110.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "A_mv_x = torch.mv(A, x)\n",
    "print(A_mv_x)\n",
    "print(\"---------等同于-------------------\")\n",
    "Ax_sum = (A * x).sum(axis=1)\n",
    "print(Ax_sum)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T03:27:03.589601500Z",
     "start_time": "2023-12-09T03:27:03.578522600Z"
    }
   },
   "id": "34c2d1339276684b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.9. 矩阵-矩阵乘法\n",
    "![image_Snipaste_2023-12-09_11-28-40.png](./assets/Snipaste_2023-12-09_15-45-44.png)\n",
    "\n",
    "矩阵乘法要求： 矩阵A(n*k) 和矩阵B(k*m)他们两个中 矩阵A的列数需要等于矩阵B的行数\n",
    "矩阵-矩阵乘法可以简单地称为矩阵乘法，不应与“Hadamard积”混淆。\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fba5734891b633e4"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: torch.Size([5, 4])\n",
      "B: torch.Size([4, 3])\n",
      "tensor([[ 6.,  6.,  6.],\n",
      "        [22., 22., 22.],\n",
      "        [38., 38., 38.],\n",
      "        [54., 54., 54.],\n",
      "        [70., 70., 70.]])\n"
     ]
    }
   ],
   "source": [
    "B = torch.ones(4, 3)\n",
    "A = A\n",
    "print(\"A:\", A.shape)\n",
    "print(\"B:\", B.shape)\n",
    "mm_AB = torch.mm(A, B)\n",
    "\n",
    "print(mm_AB)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T03:47:02.241711Z",
     "start_time": "2023-12-09T03:47:02.231720700Z"
    }
   },
   "id": "e53e8a5cb00b6902"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.10. 范数\n",
    "\n",
    "线性代数中最有用的一些运算符是范数（norm）。 非正式地说，向量的范数是表示一个向量有多大。 这里考虑的大小（size）概念不涉及维度，而是分量的大小。\n",
    "![image_Snipaste_2023-12-09_11-37-11.png](./assets/Snipaste_2023-12-09_15-46-03.png)\n",
    "\n",
    "\n",
    "![image_Snipaste_2023-12-09_11-52-02.png](./assets/Snipaste_2023-12-09_15-46-16.png)\n",
    "![image_Snipaste_2023-12-09_11-54-20.png](./assets/Snipaste_2023-12-09_15-46-32.png)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "173c7efdd4b2e4a7"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.)\n",
      "------------\n",
      "tensor(7.)\n",
      "------------\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "u = torch.tensor([3.0, -4.0])\n",
    "norm = torch.norm(u)\n",
    "print(norm)\n",
    "print(\"------------\")\n",
    "abs_sum = torch.abs(u).sum()\n",
    "print(abs_sum)\n",
    "print(\"------------\")\n",
    "frobenius = torch.norm(torch.ones((4, 9)))\n",
    "print(frobenius)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T03:57:56.133740200Z",
     "start_time": "2023-12-09T03:57:56.129909900Z"
    }
   },
   "id": "c38df6a01d143a5c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3.10.1. 范数和目标\n",
    "在深度学习中，我们经常试图解决优化问题： 最大化分配给观测数据的概率; 最小化预测和真实观测之间的距离。 用向量表示物品（如单词、产品或新闻文章），以便最小化相似项目之间的距离，最大化不同项目之间的距离。 目标，或许是深度学习算法最重要的组成部分（除了数据），通常被表达为范数。\n",
    "\n",
    "### 2.3.11. 关于线性代数的更多信息\n",
    "仅用一节，我们就教会了阅读本书所需的、用以理解现代深度学习的线性代数。 线性代数还有很多，其中很多数学对于机器学习非常有用。 例如，矩阵可以分解为因子，这些分解可以显示真实世界数据集中的低维结构。 机器学习的整个子领域都侧重于使用矩阵分解及其向高阶张量的泛化，来发现数据集中的结构并解决预测问题。 当开始动手尝试并在真实数据集上应用了有效的机器学习模型，你会更倾向于学习更多数学。 因此，这一节到此结束，本书将在后面介绍更多数学知识。\n",
    "\n",
    "如果渴望了解有关线性代数的更多信息，可以参考线性代数运算的在线附录(https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/geometry-linear-algebraic-ops.html)或其他优秀资源。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c645097fc2ec31a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a78c79fb6afb438b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2c8539d854202750"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "47fd62359a324e8f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
